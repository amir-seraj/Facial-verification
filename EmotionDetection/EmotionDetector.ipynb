{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten,Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs Available: 1\n"
     ]
    }
   ],
   "source": [
    "# Configure TensorFlow for GPU usage\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Enable memory growth for the GPU\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPUs Available: {len(gpus)}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error configuring GPU: {e}\")\n",
    "else:\n",
    "    print(\"No GPU detected. Training will use CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen=ImageDataGenerator(rescale=1./255)\n",
    "validation_data_gen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=train_data_gen.flow_from_directory(\"./data/train\",target_size=(48,48),batch_size=64,color_mode=\"grayscale\",class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator=validation_data_gen.flow_from_directory(\"./data/train\",target_size=(48,48),batch_size=64,color_mode=\"grayscale\",class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model.add(Input(shape=(48, 48, 1)))\n",
    "emotion_model.add(Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
    "emotion_model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "emotion_model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model.add(Conv2D(128,kernel_size=(3,3),activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "emotion_model.add(Conv2D(128,kernel_size=(3,3),activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "emotion_model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model.add(Flatten())\n",
    "emotion_model.add(Dense(1024,activation='relu'))\n",
    "emotion_model.add(Dropout(0.5))\n",
    "emotion_model.add(Dense(7,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model.compile(loss=\"categorical_crossentropy\",optimizer=Adam(learning_rate=0.0001, decay=1e-6),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "448/448 [==============================] - 74s 146ms/step - loss: 1.8057 - accuracy: 0.2544 - val_loss: 1.7183 - val_accuracy: 0.3267\n",
      "Epoch 2/50\n",
      "448/448 [==============================] - 61s 136ms/step - loss: 1.6377 - accuracy: 0.3587 - val_loss: 1.5426 - val_accuracy: 0.4124\n",
      "Epoch 3/50\n",
      "448/448 [==============================] - 64s 143ms/step - loss: 1.5292 - accuracy: 0.4087 - val_loss: 1.4566 - val_accuracy: 0.4452\n",
      "Epoch 4/50\n",
      "448/448 [==============================] - 59s 132ms/step - loss: 1.4572 - accuracy: 0.4419 - val_loss: 1.3677 - val_accuracy: 0.4805\n",
      "Epoch 5/50\n",
      "448/448 [==============================] - 62s 139ms/step - loss: 1.3977 - accuracy: 0.4662 - val_loss: 1.3508 - val_accuracy: 0.4865\n",
      "Epoch 6/50\n",
      "448/448 [==============================] - 62s 138ms/step - loss: 1.3456 - accuracy: 0.4906 - val_loss: 1.2758 - val_accuracy: 0.5229\n",
      "Epoch 7/50\n",
      "448/448 [==============================] - 62s 138ms/step - loss: 1.3018 - accuracy: 0.5092 - val_loss: 1.2284 - val_accuracy: 0.5458\n",
      "Epoch 8/50\n",
      "448/448 [==============================] - 62s 138ms/step - loss: 1.2651 - accuracy: 0.5170 - val_loss: 1.1757 - val_accuracy: 0.5594\n",
      "Epoch 9/50\n",
      "448/448 [==============================] - 62s 138ms/step - loss: 1.2328 - accuracy: 0.5349 - val_loss: 1.1606 - val_accuracy: 0.5699\n",
      "Epoch 10/50\n",
      "448/448 [==============================] - 62s 139ms/step - loss: 1.1989 - accuracy: 0.5485 - val_loss: 1.1050 - val_accuracy: 0.5894\n",
      "Epoch 11/50\n",
      "448/448 [==============================] - 62s 139ms/step - loss: 1.1699 - accuracy: 0.5616 - val_loss: 1.0809 - val_accuracy: 0.5997\n",
      "Epoch 12/50\n",
      "448/448 [==============================] - 62s 139ms/step - loss: 1.1477 - accuracy: 0.5702 - val_loss: 1.0588 - val_accuracy: 0.6110\n",
      "Epoch 13/50\n",
      "448/448 [==============================] - 62s 139ms/step - loss: 1.1224 - accuracy: 0.5816 - val_loss: 1.0183 - val_accuracy: 0.6246\n",
      "Epoch 14/50\n",
      "448/448 [==============================] - 63s 140ms/step - loss: 1.0967 - accuracy: 0.5871 - val_loss: 0.9786 - val_accuracy: 0.6378\n",
      "Epoch 15/50\n",
      "448/448 [==============================] - 63s 140ms/step - loss: 1.0773 - accuracy: 0.5970 - val_loss: 0.9613 - val_accuracy: 0.6529\n",
      "Epoch 16/50\n",
      "448/448 [==============================] - 63s 141ms/step - loss: 1.0518 - accuracy: 0.6065 - val_loss: 0.9196 - val_accuracy: 0.6673\n",
      "Epoch 17/50\n",
      "448/448 [==============================] - 63s 140ms/step - loss: 1.0295 - accuracy: 0.6160 - val_loss: 0.9186 - val_accuracy: 0.6814\n",
      "Epoch 18/50\n",
      "448/448 [==============================] - 63s 140ms/step - loss: 1.0064 - accuracy: 0.6264 - val_loss: 0.8965 - val_accuracy: 0.6822\n",
      "Epoch 19/50\n",
      "448/448 [==============================] - 63s 141ms/step - loss: 0.9859 - accuracy: 0.6363 - val_loss: 0.8720 - val_accuracy: 0.6922\n",
      "Epoch 20/50\n",
      "448/448 [==============================] - 63s 140ms/step - loss: 0.9606 - accuracy: 0.6433 - val_loss: 0.8223 - val_accuracy: 0.7144\n",
      "Epoch 21/50\n",
      "448/448 [==============================] - 63s 140ms/step - loss: 0.9402 - accuracy: 0.6552 - val_loss: 0.8045 - val_accuracy: 0.7261\n",
      "Epoch 22/50\n",
      "448/448 [==============================] - 63s 141ms/step - loss: 0.9227 - accuracy: 0.6590 - val_loss: 0.7587 - val_accuracy: 0.7536\n",
      "Epoch 23/50\n",
      "448/448 [==============================] - 63s 140ms/step - loss: 0.9030 - accuracy: 0.6669 - val_loss: 0.7395 - val_accuracy: 0.7460\n",
      "Epoch 24/50\n",
      "448/448 [==============================] - 63s 140ms/step - loss: 0.8738 - accuracy: 0.6786 - val_loss: 0.7042 - val_accuracy: 0.7687\n",
      "Epoch 25/50\n",
      "448/448 [==============================] - 63s 141ms/step - loss: 0.8587 - accuracy: 0.6848 - val_loss: 0.6832 - val_accuracy: 0.7732\n",
      "Epoch 26/50\n",
      "448/448 [==============================] - 63s 140ms/step - loss: 0.8339 - accuracy: 0.6936 - val_loss: 0.6472 - val_accuracy: 0.7893\n",
      "Epoch 27/50\n",
      "448/448 [==============================] - 63s 140ms/step - loss: 0.8187 - accuracy: 0.6981 - val_loss: 0.6360 - val_accuracy: 0.8076\n",
      "Epoch 28/50\n",
      "448/448 [==============================] - 63s 140ms/step - loss: 0.8005 - accuracy: 0.7033 - val_loss: 0.5851 - val_accuracy: 0.8133\n",
      "Epoch 29/50\n",
      "448/448 [==============================] - 63s 141ms/step - loss: 0.7795 - accuracy: 0.7118 - val_loss: 0.5871 - val_accuracy: 0.8285\n",
      "Epoch 30/50\n",
      "448/448 [==============================] - 63s 140ms/step - loss: 0.7519 - accuracy: 0.7265 - val_loss: 0.5343 - val_accuracy: 0.8390\n",
      "Epoch 31/50\n",
      "448/448 [==============================] - 63s 141ms/step - loss: 0.7269 - accuracy: 0.7337 - val_loss: 0.5249 - val_accuracy: 0.8551\n",
      "Epoch 32/50\n",
      "448/448 [==============================] - 63s 140ms/step - loss: 0.7059 - accuracy: 0.7423 - val_loss: 0.4825 - val_accuracy: 0.8643\n",
      "Epoch 33/50\n",
      "448/448 [==============================] - 63s 140ms/step - loss: 0.6859 - accuracy: 0.7479 - val_loss: 0.4540 - val_accuracy: 0.8807\n",
      "Epoch 34/50\n",
      "448/448 [==============================] - 63s 140ms/step - loss: 0.6646 - accuracy: 0.7570 - val_loss: 0.4419 - val_accuracy: 0.8771\n",
      "Epoch 35/50\n",
      "448/448 [==============================] - 63s 141ms/step - loss: 0.6485 - accuracy: 0.7634 - val_loss: 0.4153 - val_accuracy: 0.8970\n",
      "Epoch 36/50\n",
      "448/448 [==============================] - 63s 140ms/step - loss: 0.6253 - accuracy: 0.7721 - val_loss: 0.3906 - val_accuracy: 0.9008\n",
      "Epoch 37/50\n",
      "448/448 [==============================] - 63s 140ms/step - loss: 0.6077 - accuracy: 0.7818 - val_loss: 0.3611 - val_accuracy: 0.9075\n",
      "Epoch 38/50\n",
      "448/448 [==============================] - 63s 140ms/step - loss: 0.5866 - accuracy: 0.7877 - val_loss: 0.3360 - val_accuracy: 0.9223\n",
      "Epoch 39/50\n",
      "448/448 [==============================] - 63s 141ms/step - loss: 0.5660 - accuracy: 0.7961 - val_loss: 0.3281 - val_accuracy: 0.9226\n",
      "Epoch 40/50\n",
      "448/448 [==============================] - 63s 141ms/step - loss: 0.5545 - accuracy: 0.8002 - val_loss: 0.3054 - val_accuracy: 0.9323\n",
      "Epoch 41/50\n",
      "448/448 [==============================] - 63s 140ms/step - loss: 0.5393 - accuracy: 0.8058 - val_loss: 0.2824 - val_accuracy: 0.9379\n",
      "Epoch 42/50\n",
      "448/448 [==============================] - 63s 141ms/step - loss: 0.5202 - accuracy: 0.8103 - val_loss: 0.2625 - val_accuracy: 0.9480\n",
      "Epoch 43/50\n",
      "448/448 [==============================] - 63s 142ms/step - loss: 0.5091 - accuracy: 0.8132 - val_loss: 0.2457 - val_accuracy: 0.9579\n",
      "Epoch 44/50\n",
      "448/448 [==============================] - 62s 138ms/step - loss: 0.4869 - accuracy: 0.8245 - val_loss: 0.2247 - val_accuracy: 0.9643\n",
      "Epoch 45/50\n",
      "448/448 [==============================] - 59s 131ms/step - loss: 0.4746 - accuracy: 0.8274 - val_loss: 0.2245 - val_accuracy: 0.9630\n",
      "Epoch 46/50\n",
      "448/448 [==============================] - 52s 116ms/step - loss: 0.4575 - accuracy: 0.8341 - val_loss: 0.2070 - val_accuracy: 0.9700\n",
      "Epoch 47/50\n",
      "448/448 [==============================] - 55s 123ms/step - loss: 0.4425 - accuracy: 0.8410 - val_loss: 0.1826 - val_accuracy: 0.9717\n",
      "Epoch 48/50\n",
      "448/448 [==============================] - 58s 130ms/step - loss: 0.4326 - accuracy: 0.8442 - val_loss: 0.1711 - val_accuracy: 0.9742\n",
      "Epoch 49/50\n",
      "448/448 [==============================] - 57s 126ms/step - loss: 0.4166 - accuracy: 0.8487 - val_loss: 0.1684 - val_accuracy: 0.9741\n",
      "Epoch 50/50\n",
      "448/448 [==============================] - 57s 126ms/step - loss: 0.4023 - accuracy: 0.8537 - val_loss: 0.1542 - val_accuracy: 0.9780\n"
     ]
    }
   ],
   "source": [
    "emotion_model_info=emotion_model.fit(train_generator,steps_per_epoch=28709//64,epochs=50,validation_data=validation_generator,validation_steps=7178//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure emotion_model is properly initialized\n",
    "if emotion_model is not None:\n",
    "    # Convert model to JSON\n",
    "    model_json = emotion_model.to_json()\n",
    "    \n",
    "    # Save the model JSON\n",
    "    with open(\"emotion_model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    \n",
    "    # Save the model weights\n",
    "    emotion_model.save_weights(\"emotion_model.weights.h5\")\n",
    "else:\n",
    "    print(\"Error: emotion_model is None\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
